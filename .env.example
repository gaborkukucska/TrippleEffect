# START OF FILE .env.example
# Environment variables for TrippleEffect

# --- Provider API Keys ---
# Fill in keys ONLY for the providers you intend to use.
# The framework will check reachability and discover models accordingly.
# You can provide multiple API keys per provider by adding a number like so `OPENROUTER_API_KEY_2=your_secod_key` at the end of the corresponding environment variable.
# Example:
# OPENROUTER_API_KEY=key-001
# OPENROUTER_API_KEY_2=key-002
# OPENROUTER_API_KEY_3=key-003

OPENAI_API_KEY=your_openai_api_key_here
OPENROUTER_API_KEY=your_openrouter_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here
GOOGLE_API_KEY=your_google_ai_studio_api_key_here
# Note: Hugging Face often uses tokens passed via headers or specific client args,
# Add relevant HF token variable if a dedicated provider is implemented.
# HUGGINGFACE_TOKEN=your_huggingface_token_here
DEEPSEEK_API_KEY=your_deepseek_api_key_here
# Add other provider keys as needed...

# --- Provider Base URLs (Optional Overrides) ---
# Framework attempts auto-discovery for Ollama/LiteLLM on localhost if these are commented out.
# Defaults are used for OpenRouter/OpenAI if commented out.
# Uncomment and set ONLY if your service is running elsewhere or you need a specific endpoint.

# OLLAMA_BASE_URL=http://<ollama_server_ip_or_hostname>:11434
# LITELLM_BASE_URL=http://<litellm_server_ip_or_hostname>:<port>
# OPENROUTER_BASE_URL=https://openrouter.ai/api/v1
# OPENAI_BASE_URL=https://api.openai.com/v1
# ANTHROPIC_BASE_URL= # If needed
# GOOGLE_BASE_URL= # If needed
# DEEPSEEK_BASE_URL=https://api.deepseek.com

# --- OpenRouter Specific (Optional) ---
# Set your custom OpenRouter Referer (otherwise the default is used)
OPENROUTER_REFERER=http://localhost:8000/TrippleEffect

# --- Model Tier Selection ---
# Selects which models to consider based on cost tier (mainly for OpenRouter).
# Valid values: "FREE", "ALL" (default)
# - FREE: Only uses models identified as free (e.g., matching ':free' suffix on OpenRouter), and all local models.
# - ALL: Considers all discovered models from configured providers including paid providers.
MODEL_TIER=FREE

# --- Project/Session Storage ---
# Optional: Specify a different base directory for project/session data.
# Defaults to 'projects' directory within the TrippleEffect root.
PROJECTS_BASE_DIR=projects

# --- Tool Configuration ---
# Required for GitHub Tool functionality
GITHUB_ACCESS_TOKEN=your_github_personal_access_token_here

# --- Logging Configuration (Optional) ---
# LOG_LEVEL=DEBUG # Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
